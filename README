README file for the ID3 Decision Tree programming

Description
--------------------------------------------------
This program takes a data file as input, and a target class name and outputs
a decision tree.

Running Instructions
---------------------------
Simply navigate to the folder containing the src folder. Then run the commands~

    javac src/*.java
    java -cp ./src DecisionTree

		- input the data file name (data files are supposed in the same directory)
		- input the attribute as the target attribute (Spelled as in the data file)


Assumptions
---------------------------------------------
	- There are no missing data values.


Code Overview
---------------------------------------------------------------------
	- All classes and methods included
		- DecisionTree
		    read_data(), create_subset(), calculate_entropy(), get_splitting_attribute(),
		    build_tree(), get_user_options(), get_target_code(), create_rules()

		- ID3Node
			hasChildren(), get_targetVal()
			ID3Nodes are the nodes used in the tree, containing the entropy, data subset,
			split attribute and value, its children and parent nodes as well as the target
			value (the class of the target attribute a leaf node belongs to)
		- Rule
		    print_rule()
		    Rules are just paths through the tree, leading to the leaf nodes. Rules consist
		    of an integer code for an attribute a, its attribute value code aVal, the dataset,
		    the value of the target and a recursive Rule b, which could be another nested rule,
		    or simply a leaf node, which will be printed as the target attribute and target value.


		- DataSet
		    print_dataTable(), print_data() -- These were used only for debugging
			setter/getter methods as well
			A dataset stores the attribute names, the possible values for each of the attributes,
			and a data table containing the integer codes to map the values in the input data and
			the attribute value codes. Subsets of the data are represented as Datasets as well.

Program Flow
-----------------------------------------------------------------------------
The user options are taken for data file and target attribute. The data is read into a DataSet
object. A tree is created by first creating the root node and calling build tree with it. Build tree
is called recursively, where the entropy for the node is calculated and stored. If the entropy is 0,
then the current node is a leaf node with the target attribute classes split. If it is not a leaf node,
we get the splitting attribute and generate child nodes with their datasets as subsets defined by the
splitting attribute. For each of the new children, we call build_tree recursively. Once a leaf node is reached,
we return to the parent node and check the next child.

Once we have the tree, we call create_rules, to generate an array of rules, each rule of the form
(a is valA, then b), where b can be a nested rule, or a target attribute and target value. The rules
are generated by traversing the tree setting the a and aVal at each node, as well as the b rule.
As stated above, the b rule is generated recursively with create_rule called on the child nodes. After
the rules are generated, we recursively print the rules, replacing a, aVal, targetCode and targetVal with
their corresponding strings found in the atrNames and atrValues lists. The output tree is generated
to look like a tree by counting the level of the tree we are at, and printing that many indents before the rule.



Note: any further details can be found in the documentation in the code
